{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.server\n",
    "\n",
    "anvil.server.connect(\"WQ3UBRHS4OF3TJLPRMBMHWSA-4MAZVW7HBP3WMJIX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2858 6775\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "import os\n",
    "import anvil.media\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "\n",
    "location_image =  'C:/Users/geral/Documents/SeniorProject/Predict'\n",
    "\n",
    "@anvil.server.callable\n",
    "\n",
    "def predict_image(imageA):\n",
    "    \"\"\"Predict.\"\"\"\n",
    "    # [START automl_vision_object_detection_predict]\n",
    "    from google.cloud import automl\n",
    "    \n",
    "    with anvil.media.TempFile(imageA) as FN1:\n",
    "        #file_path = FN1\n",
    "        imgA = cv2.imread(FN1)\n",
    "        \n",
    "        height = imgA.shape[0]\n",
    "        width = imgA.shape[1]\n",
    "        \n",
    "        print(height, width)\n",
    "     \n",
    "    \n",
    "    file_path = os.path.join(location_image , 'Floorplanpredict.png')\n",
    "    \n",
    "    cv2.imwrite(file_path, imgA)\n",
    "    \n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'C:/Users/geral/Documents/SeniorProj/FloorPlans-b0febaf27c5c.json'\n",
    "\n",
    "    # TODO(developer): Uncomment and set the following variables\n",
    "    project_id = \"floorplan-274512\";\n",
    "    location = \"us-central1\";\n",
    "    model_id = \"IOD2023202550177595392\";\n",
    "    prediction_client = automl.PredictionServiceClient()\n",
    "\n",
    "    # Get the full path of the model.\n",
    "    model_full_id = prediction_client.model_path(\n",
    "        project_id, \"us-central1\", model_id\n",
    "    )\n",
    "    #file_path = 'C:/Users/geral/Documents/FloorPlans/set1_png/file_1.png'\n",
    "\n",
    "    \n",
    "    # Read the file.\n",
    "    with open(file_path, \"rb\") as content_file:\n",
    "        content = content_file.read()\n",
    "\n",
    "    image = automl.types.Image(image_bytes=content)\n",
    "    payload = automl.types.ExamplePayload(image=image)\n",
    "\n",
    "    # params is additional domain-specific parameters.\n",
    "    # score_threshold is used to filter the result\n",
    "    # https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#predictrequest\n",
    "    \n",
    "    params = {\"score_threshold\": \"0.8\"}\n",
    "\n",
    "    response = prediction_client.predict(model_full_id, payload, params)\n",
    "    \n",
    "    result_text = os.path.join(location_image , 'Floorplanpredict.txt')\n",
    "    \n",
    "        \n",
    "    print(response)\n",
    "    #print(type(response))\n",
    "            \n",
    "    count=0\n",
    "       \n",
    "    object_list = []\n",
    "    score_list = []\n",
    "    percentage_list = []\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    ###Acess JSON Payload#######\n",
    "    \n",
    "    for result in response.payload:\n",
    "        \n",
    "        bounding_box = result.image_object_detection.bounding_box\n",
    "        object_list.append(result.display_name)\n",
    "        score_list.append(result.image_object_detection.score)\n",
    "        percentage_list.append(\"{:.2%}\".format(result.image_object_detection.score)) \n",
    "        count = count+1\n",
    "        \n",
    "        for vertex in bounding_box.normalized_vertices:\n",
    "            \n",
    "        ####OBTAIN ORIGINAL COORDINATES BY MULTIPLYING NORMALIZED VALUES BY ORIGINAL DIMENSIONS######\n",
    "            org_x = int(vertex.x*width) \n",
    "            org_y = int(vertex.y*height)\n",
    "            x.append(org_x)\n",
    "            y.append(org_y)\n",
    "             \n",
    "    coords_list = list(zip(x,y))    \n",
    "    #print(coords_list)\n",
    "    #print(count)\n",
    "    print(score_list)\n",
    "    print(percentage_list)\n",
    "    \n",
    "#####count#################\n",
    "    #print(object_list)\n",
    "    c = dict(Counter(object_list))\n",
    "    #print(c)\n",
    "        \n",
    "    for k, v in c.items():\n",
    "        print(\"{} count:  {}\".format(k, v))\n",
    "  \n",
    "        \n",
    "    #pts = np.array(list_of_coords, np.int32)\n",
    "    \n",
    "   \n",
    "    i = 0\n",
    "    \n",
    "    for p, coords in enumerate(coords_list):\n",
    "        \n",
    "        if p%2 == 0:\n",
    "            c1 = coords \n",
    "            label = object_list[i]\n",
    "            score = percentage_list[i]\n",
    "            out = label +\" \"+ score\n",
    "            i=i+1\n",
    "            (a,b) = c1\n",
    "            cv2.putText(imgA,out,(a,b-10), cv2.FONT_HERSHEY_COMPLEX,1.5,(0,0,255),2)\n",
    "        else:\n",
    "            c2 = coords\n",
    "            cv2.rectangle(imgA, c1, c2, (0, 0, 255), 2)\n",
    "            \n",
    "     \n",
    "    \n",
    "  \n",
    "    cv2.imwrite(os.path.join(location_image, 'predicted.png'), imgA)\n",
    "      \n",
    "        \n",
    "        \n",
    "\n",
    "        #for result in response.payload:\n",
    "            #print(\"Predicted class name: {}\".format(result.display_name))\n",
    "            #print(\"Predicted class score: {}\".format(result.image_object_detection.score))\n",
    "            #bounding_box = result.image_object_detection.bounding_box\n",
    "            #print(\"Normalized Vertices:\")\n",
    "            #f.write(\"Predicted classname:{}\\n\".format(result.display_name))\n",
    "            #f.write(\"Predicted class score:{}\\n\".format(result.image_object_detection.score))\n",
    "            #f.write(\"Normalized vertices\\n\") \n",
    "            #for vertex in bounding_box.normalized_vertices:\n",
    "                #print(\"\\tX: {}, Y: {}\".format(vertex.x, vertex.y))\n",
    "                #f.write(\"\\tX: {}, Y: {}\\n\".format(vertex.x, vertex.y))\n",
    "                \n",
    "                #vertices = cv2.boundingRect(vertex)\n",
    "                \n",
    "             \n",
    "\n",
    "    # [END automl_vision_object_detection_predict]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
