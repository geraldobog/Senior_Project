{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Authenticated OK\n"
     ]
    }
   ],
   "source": [
    "####Package Imports####\n",
    "from skimage.metrics import structural_similarity\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import anvil.media\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "####File Locations####\n",
    "\n",
    "location_compare = 'C:/Users/geral/Documents/SeniorProject/Compare'\n",
    "location_predict = 'C:/Users/geral/Documents/SeniorProject/Predict'\n",
    "\n",
    "####Connecting to Anvil#####\n",
    "\n",
    "import anvil.server\n",
    "anvil.server.connect(\"TATIRUIDUHZPTWDWQSVZR3SN-GAK2P3JOWGIWVQHG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "####Main Comparison Function####\n",
    "\n",
    "def compare_image(file1, file2):\n",
    "    \n",
    "        with anvil.media.TempFile(file1) as FN1:\n",
    "            image1 = cv2.imread(FN1)\n",
    "        with anvil.media.TempFile(file2) as FN2: \n",
    "            image2 = cv2.imread(FN2)\n",
    "            \n",
    "            \n",
    "        dim1 = image1.shape\n",
    "        dim2 = image2.shape\n",
    "        chk_dim = np.array_equal(dim1,dim2)\n",
    "        \n",
    "        ####Normalization####\n",
    "        \n",
    "        if (chk_dim is True):\n",
    "            \n",
    "            scale_percent = 35\n",
    "\n",
    "            width1 = int(image1.shape[1] * scale_percent / 100)\n",
    "            height1 = int(image1.shape[0] * scale_percent / 100)\n",
    "\n",
    "            width2 = int(image2.shape[1] * scale_percent / 100)\n",
    "            height2 = int(image2.shape[0] * scale_percent / 100)\n",
    "\n",
    "            dsize1 = (width1, height1)\n",
    "            dsize2 = (width2, height2)\n",
    "\n",
    "            R1 = cv2.resize(image1,dsize1)\n",
    "            R2 = cv2.resize(image2,dsize2)\n",
    "        \n",
    "        \n",
    "            ####Convert to Grayscale Image####\n",
    "    \n",
    "            grayR1 = cv2.cvtColor(R1, cv2.COLOR_BGR2GRAY)\n",
    "            grayR2 = cv2.cvtColor(R2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            ####Find Similarity Index####\n",
    "       \n",
    "\n",
    "            (score, diff) = structural_similarity(grayR1, grayR2, full=True)\n",
    "\n",
    "            diff = (diff * 255).astype(\"uint8\")##convert from floating point to unsigned int for openCV\n",
    "        \n",
    "            thresh = cv2.threshold(diff, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "            cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "        \n",
    "            \n",
    "            for c in cnts:\n",
    "            \n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                cv2.rectangle(R1, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                cv2.rectangle(R2, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                coords1 = np.asarray(c)\n",
    "                coords2 = np.squeeze(coords1, axis = 1)\n",
    "                \n",
    "\n",
    "            \n",
    "            np.savetxt((os.path.join(location_compare  , 'Coordinates_Compare.csv')),coords2, fmt = '%.2f', delimiter =',')\n",
    "            \n",
    "            ####Save Images to Local File Path####\n",
    "       \n",
    "            cv2.imwrite(os.path.join(location_compare  , 'Floorplan1.png'), R1)\n",
    "            cv2.imwrite(os.path.join(location_compare  , 'Floorplan2.png'), R2)\n",
    "            cv2.imwrite(os.path.join(location_compare  , 'Difference.png'), diff)\n",
    "            cv2.imwrite(os.path.join(location_compare  , 'Threshold.png'), thresh)\n",
    "\n",
    "            return(float(score))\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return('error')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_image():\n",
    "    \n",
    "    f1 = anvil.media.from_file((os.path.join(location_compare , 'Floorplan1.png')), \"img/png\")\n",
    "    f2 = anvil.media.from_file((os.path.join(location_compare, 'Floorplan2.png')), \"img/png\")\n",
    "    diff = anvil.media.from_file((os.path.join(location_compare , 'Difference.png')), \"img/png\")\n",
    "        \n",
    "    return(f1, f2, diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_coordinates_csv():\n",
    "    coordscsv = anvil.media.from_file((os.path.join(location_compare , 'Coordinates_Compare.csv')), \"text/csv\")\n",
    "    return coordscsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_images_download():\n",
    "    f1_d = anvil.media.from_file((os.path.join(location_compare , 'Floorplan1.png')), \"img/png\")\n",
    "    f2_d = anvil.media.from_file((os.path.join(location_compare, 'Floorplan2.png')), \"img/png\")\n",
    "    diff_d = anvil.media.from_file((os.path.join(location_compare, 'Difference.png')), \"img/png\")\n",
    "    \n",
    "    return (f1_d,f2_d,diff_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "####\n",
    "\n",
    "####\n",
    "\n",
    "@anvil.server.callable\n",
    "\n",
    "def predict_image(imageA):\n",
    "    \"\"\"Predict.\"\"\"\n",
    "    # [START automl_vision_object_detection_predict]\n",
    "    from google.cloud import automl\n",
    "    \n",
    "    with anvil.media.TempFile(imageA) as FN1:\n",
    "\n",
    "        imgA = cv2.imread(FN1)\n",
    "        height = imgA.shape[0]\n",
    "        width = imgA.shape[1]\n",
    "    \n",
    "     \n",
    "    \n",
    "    file_path = os.path.join(location_predict , 'Floorplanpredict.png')\n",
    "    \n",
    "    cv2.imwrite(file_path, imgA)\n",
    "    \n",
    "    ####Load Google API Credentials####\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'C:/Users/geral/Documents/SeniorProj/FloorPlans-b0febaf27c5c.json'\n",
    "\n",
    "    ####Variables to Choose Model####\n",
    "    project_id = \"floorplan-274512\";\n",
    "    location = \"us-central1\";\n",
    "    model_id = \"IOD1541394355862896640\";\n",
    "    prediction_client = automl.PredictionServiceClient()\n",
    "\n",
    "    ####Obtain Full Path of Model####\n",
    "    \n",
    "    model_full_id = prediction_client.model_path(project_id, location , model_id)\n",
    "    \n",
    "    #Open Image Through File Path and Take Bytes\n",
    "    \n",
    "    with open(file_path, \"rb\") as content_file:\n",
    "        content = content_file.read()\n",
    "\n",
    "    image = automl.types.Image(image_bytes=content)\n",
    "    payload = automl.types.ExamplePayload(image=image)\n",
    "\n",
    "    # score_threshold is used to filter the result\n",
    "    # https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#predictrequest\n",
    "    \n",
    "    ###Access JSON Payload#######\n",
    "    \n",
    "    ###Google API Function to Return Objects with Score >= 0.8\n",
    "    params = {\"score_threshold\": \"0.8\"} \n",
    "    response = prediction_client.predict(model_full_id, payload, params)\n",
    "   \n",
    "   \n",
    "            \n",
    "        \n",
    "    ####Prepare Lists for Appending Information####\n",
    "    object_count = 0\n",
    "    object_list = []\n",
    "    score_list = []\n",
    "    percentage_list = []\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    ###Iterate through JSON Payload#######\n",
    "    \n",
    "    for result in response.payload:\n",
    "        \n",
    "        bounding_box = result.image_object_detection.bounding_box\n",
    "        object_list.append(result.display_name)\n",
    "        score_list.append(result.image_object_detection.score)\n",
    "        percentage_list.append(\"{:.2%}\".format(result.image_object_detection.score)) \n",
    "        object_count = object_count + 1\n",
    "        \n",
    "         ####Iterate Through Bounding Box in Payload####\n",
    "        for vertex in bounding_box.normalized_vertices:\n",
    "            \n",
    "        ####Multiply Normalized Vertex By Original Dimensions to Get Orignal Vertices######\n",
    "        \n",
    "            org_x = int(vertex.x*width) \n",
    "            org_y = int(vertex.y*height)\n",
    "            x.append(org_x)\n",
    "            y.append(org_y)\n",
    "             \n",
    "    ###Create a Tuple of the Original Vertices####\n",
    "    coords_list = list(zip(x,y))\n",
    "    np.savetxt((os.path.join(location_predict  , 'Coordinates_Predictions.csv')),coords_list, fmt = '%.2f', delimiter =',')\n",
    "    \n",
    "   \n",
    "    object_count_list = dict(Counter(object_list))\n",
    "        \n",
    "    \n",
    "    \n",
    "    with open(os.path.join(location_predict  , 'Objects_Count.txt'), \"w\") as text_file:\n",
    "        text_file.write(\"Elements in the Floorplan\\n\") \n",
    "        for k, v in object_count_list.items():\n",
    "            text_file.write(\"{} : {}\\n\".format(k, v))\n",
    "        text_file.write(\"Total Elements: {}\\n\".format(object_count)) \n",
    "    \n",
    "   \n",
    "    i = 0\n",
    "    \n",
    "    for p, coords in enumerate(coords_list):\n",
    "        \n",
    "        if p%2 == 0:\n",
    "            c1 = coords \n",
    "            label = object_list[i]\n",
    "            score = percentage_list[i]\n",
    "            out = label +\" \"+ score\n",
    "            i=i+1\n",
    "            (a,b) = c1\n",
    "            cv2.putText(imgA,out,(a,b-10), cv2.FONT_HERSHEY_COMPLEX,1.5,(0,0,255),2)\n",
    "        else:\n",
    "            c2 = coords\n",
    "            cv2.rectangle(imgA, c1, c2, (0, 0, 255), 2)\n",
    "            \n",
    "     \n",
    "    \n",
    "  \n",
    "    cv2.imwrite(os.path.join(location_predict, 'predicted.png'), imgA)\n",
    "      \n",
    "                \n",
    "             \n",
    "\n",
    "    # [END automl_vision_object_detection_predict]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_predict_image():\n",
    "    preds = anvil.media.from_file((os.path.join(location_predict , 'predicted.png')), \"img/png\")\n",
    "    return preds\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_predict_image_download():\n",
    "    preds = anvil.media.from_file((os.path.join(location_predict , 'predicted.png')), \"img/png\")\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_predict_csv():\n",
    "    preds = anvil.media.from_file((os.path.join(location_predict , 'Coordinates_Predictions.csv')), \"txt/csv\")\n",
    "    return preds\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_predict_results():\n",
    "    results = anvil.media.from_file((os.path.join(location_predict , 'Objects_Count.txt')), \"txt/plain\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "\n",
    "def return_predict_results_download():\n",
    "    results = anvil.media.from_file((os.path.join(location_predict , 'Objects_Count.txt')), \"txt/plain\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
